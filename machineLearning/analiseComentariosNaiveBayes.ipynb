{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0dca056",
   "metadata": {},
   "source": [
    "## Análise de sentimentos com algoritmo Naive Bayes\n",
    "\n",
    "Este código demonstra a aplicação do algoritmo Naive Bayes em um projeto de análise de sentimentos. Foram utilizadas as bibliotecas pandas, numpy, tabulate, sklearn (CountVectorizer e MultinomialNB) e joblib para persistir o modelo treinado. O objetivo é classificar comentários de produtos como positivos ou negativos com base em sua pontuação geral e no texto do comentário, sendo comentários com nota maior ou igual a 3 considerados positivos, e abaixo disso negativos.\n",
    "\n",
    "O algoritmo Naive Bayes é um método de classificação probabilístico simples, baseado no teorema de Bayes, com uma suposição \"ingênua\" de independência entre os recursos. Ele é frequentemente utilizado em problemas de análise de sentimentos e classificação de textos. Na prática, o algoritmo calcula a probabilidade de um comentário ser positivo ou negativo com base nas palavras presentes nele, assumindo que a presença de cada palavra é independente das outras (daí o \"ingênuo\").\n",
    "\n",
    "O código carrega um conjunto de dados de avaliações de produtos, remove linhas com dados ausentes, cria uma nova coluna de classificação com base na pontuação geral e nos separa os comentários e suas classes. Em seguida, ele utiliza a classe CountVectorizer para converter os comentários em vetores de contagem de palavras. A vetorização de palavras é o processo de transformar textos em representações numéricas que possam ser usadas por algoritmos de aprendizado de máquina. No contexto do Naive Bayes para análise de sentimentos, a vetorização de palavras geralmente envolve a criação de um vocabulário com todas as palavras únicas nos textos e, em seguida, a contagem de quantas vezes cada palavra aparece em cada texto. Isso resulta em uma matriz em que cada linha representa um texto e cada coluna representa uma palavra do vocabulário, com os valores indicando a frequência de cada palavra no texto.\n",
    "\n",
    "Os termos frequentes são avaliados com base em sua presença e frequência nos textos. No contexto da análise de sentimentos, palavras que aparecem com frequência em comentários positivos podem ser consideradas como indicativas de sentimentos positivos, enquanto palavras que aparecem com frequência em comentários negativos podem ser consideradas como indicativas de sentimentos negativos. O Naive Bayes utiliza essas frequências para calcular a probabilidade de um texto pertencer a uma determinada classe (positiva ou negativa), levando em conta a frequência de cada palavra no texto e a frequência das palavras em cada classe.\n",
    "\n",
    "Em seguida, os vetores de contagem de palavras são usados para treinar um modelo Multinomial Naive Bayes. Esse modelo é então salvo em um arquivo para uso futuro.\n",
    "\n",
    "Para testar o modelo, são fornecidos alguns comentários de teste que são transformados em vetores de contagem de palavras e passados para o modelo carregado, que faz previsões sobre se os comentários são positivos ou negativos. O resultado das previsões é então exibido no console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d77555d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\augus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\augus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from IPython.display import display\n",
    "\n",
    "# Baixando palavras comuns de pt.\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51fe760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o conjunto de dados\n",
    "dataset = pd.read_csv(\"C:\\\\fatec\\\\B2W-Reviews01\\\\B2W-Reviews01.csv\", usecols=['overall_rating', 'review_text'])\n",
    "\n",
    "# Remover linhas com valores em branco\n",
    "dataset = dataset.dropna(subset=['review_text'])\n",
    "\n",
    "# Separar os dados em features (X) e target (Y)\n",
    "X = dataset['review_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a578a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização e pré-processamento dos dados\n",
    "X_preprocessed = []\n",
    "for text in X:\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stopwords.words('portuguese')]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    X_preprocessed.append(preprocessed_text)\n",
    "\n",
    "\n",
    "# Criar um objeto CountVectorizer para vetorizar os dados\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X_preprocessed)\n",
    "\n",
    "# Dividir os dados em conjunto de treinamento e teste\n",
    "X_train, X_test = train_test_split(X_vectorized, test_size=0.25, random_state=42)\n",
    "\n",
    "# Criar e treinar o modelo Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train)\n",
    "\n",
    "# Avaliar o modelo\n",
    "accuracy = model.score(X_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e305d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive' 'Positive' 'Positive' 'Negative' 'Negative' 'Negative']\n"
     ]
    }
   ],
   "source": [
    "# Salva o modelo e o vetorizador em um único arquivo, no mesmo diretório desse notebook\n",
    "dump((modelo, vectorizer), 'modelo_e_vetorizador.joblib')\n",
    "\n",
    "# Carrega o modelo e o vetorizador do arquivo\n",
    "modelo_carregado, vetorizador_carregado = load('modelo_e_vetorizador.joblib')\n",
    "\n",
    "# Usa o modelo e o vetorizador carregados para fazer previsões\n",
    "freq_testes = vetorizador_carregado.transform(testes)\n",
    "previsoes = modelo_carregado.predict(freq_testes)\n",
    "print(previsoes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_PI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
